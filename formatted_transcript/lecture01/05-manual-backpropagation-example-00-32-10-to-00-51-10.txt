
So let's now fill in those gradients and actually do backpropagation manually.
So let's start filling in these gradients and start all the way at the end, as
I mentioned here. First, we are interested to fill in this gradient here. So
what is the derivative of L with respect to L? In other words, if I change L by
a tiny amount h, how much does L change? It changes by h. So it's proportional,
and therefore the derivative will be 1. We can of course measure these or
estimate these numerical gradients numerically just like we've seen before. So
if I take this expression and I create a def lol function here and put this
here. Now the reason I'm creating a gating function lol here is because I don't
want to pollute or mess up the global scope here. This is just kind of like a
little staging area, and as you know in Python, all of these will be local
variables to this function, so I'm not changing any of the global scope here.
So here L1 will be L, and then copying and pasting this expression, we're going
to add a small amount H in for example A, right? This would be measuring the
derivative of L with respect to A. So here this will be L2, and then we want to
print test derivative. So print L2 minus L1, which is how much L changed, and
then normalize it by H. So this is the rise over run, and we have to be careful
because L is a valid node, so we actually want its data so that these are
floats dividing by H. This should print the derivative of L with respect to A
because A is the one that we bumped a little bit by H. So what is the
derivative of L with respect to A? It's 6. Okay, and obviously if we change L
by H, then that would be here effectively. This looks really awkward, but
changing L by H, you see the derivative here is 1. That's kind of like the base
case of what we are doing here. So basically we can come up here and we can
manually set l.grad to 1. This is our manual backpropagation. l.grad is 1, and
let's redraw. We’ll see that we filled in grad is 1 for l. We're now going to
continue the backpropagation. So let's here look at the derivatives of L with
respect to D and F. Let's do D first. What we are interested in, if I create a
markdown on here, is we'd like to know, basically we have that L is D times F,
and we'd like to know what is dL by dD. What is that? If you know your
calculus, L is D times F, so what is dL by dD? It would be F. If you don't
believe me, we can also just derive it because the proof would be fairly
straightforward. We go to the definition of the derivative, which is F of x
plus h minus F of x, divide h, as a limit of h goes to 0 of this kind of
expression. So when we have L is D times F, then increasing D by h would give
us the output of D plus h times F. That's basically F of x plus h, right? Minus
D times F. And then divide h. And symbolically, expanding out here, we would
have basically D times F plus H times F minus D times F. Divide h. And then you
see how the DF minus DF cancels, so you're left with H times F. Divide h, which
is F. So in the limit as h goes to 0 of the derivative definition, we just get
F in the case of D times F. So symmetrically, dL by dF will just be D. So what
we have is that F.grad we see now is just the value of D, which is 4, and we
see that D.grad is just the value of F. The value of F is -2. So we'll set
those manually. Let me erase this markdown node and then let's redraw what we
have. Okay. And let's just make sure that these were correct. So we seem to
think that dL by dD is -2. So let's double check. Let me erase this plus h from
before. Now we want the derivative with respect to F. So let's just come here
when I create F and let's do a plus h here. This should print a derivative of L
with respect to F. So we expect to see 4. Yeah, and this is 4 up to floating
point funkiness. Then dL by dD should be F, which is -2. Grad is -2. If we,
again, come here and we change D, D.data plus equals h right here. So we
expect, so we've added a little h, and then we see how L changed. We expect to
print -2. There we go. So we've numerically verified. What we're doing here is
kind of like an inline gradient check. Gradient check is when we are deriving
this like backpropagation and getting the derivatives we expect to all the
intermediate results. The numerical gradient is just, you know, estimating it
using a small step size. Now we're getting to the crux of backpropagation. This
will be the most important node to understand because if you understand the
gradient for this node, you understand all of backpropagation and all of
training of neural nets, basically.

So we need to derive dL by dC. In other words, the derivative of L with respect
to C because we've computed all these other gradients already. Now we're coming
here and we're continuing the backpropagation manually. So we want dL by dC,
and then we'll also derive dL by dE. Now here's the problem. How do we derive
dL by dC? We actually know the derivative L with respect to D, so we know how L
is sensitive to D. But how is L sensitive to C? So if we wiggle C, how does
that impact L through D? We know dL by dC, and we also here know how C impacts
D. Just very intuitively, if you know the impact that C is having on D and the
impact that D is having on L, then you should be able to somehow put that
information together to figure out how C impacts L. Indeed, this is what we can
actually do. Specifically, concentrating on D first, let’s look at what is the
derivative basically of D with respect to C. In other words, what is dD by dC?
So here we know that D is C plus E. That's what we know. Now we're interested
in dD by dC. If you just know your calculus again, and you remember that
differentiating C plus E with respect to C, you know that that gives you 1.0.
We can also go back to the basics and derive this. We can go to our F of x plus
h minus F of x divided by h as the definition of a derivative as h goes to 0.
Here, focusing on C and its effect on D, we can do the F of x plus h will be C
incremented by h plus C. That's the first evaluation of our function minus C
plus C. Then divide h. What is this? Expanding this out, this will be C plus h
plus E minus C minus E, divided by h. You see here how C minus C cancels and E
minus E cancels, we're left with h over h, which is 1.0. By symmetry, also, dD
by dE will be 1.0 as well. So basically, the derivative of a sum expression is
very simple. I call this the local derivative because we have the final output
value all the way at the end of this graph. Now we're like a small node here.
This is a little plus node. This little plus node doesn't know anything about
the rest of the graph that it's embedded in. All it knows is that it did a
plus. It took a C and an E, added them, and created a D. This plus node also
knows the local influence of C on D, or rather the derivative of D with respect
to C. It also knows the derivative of D with respect to E, but that's not what
we want; that’s just a local derivative. What we actually want is dL by dC, and
L is here just one step away, but in general, this little plus node could be
embedded in a massive graph. So again we know how L impacts D, and now we know
how C and E impact D. How do we put that information together to write dL by
dC? The answer is the chain rule in calculus.

I pulled up the chain rule here from Wikipedia, and I'm going to go through
this very briefly. The chain rule can be very confusing and calculus can be
very confusing. Like this is the way I learned the chain rule, and it was very
confusing. What is happening? It's complicated. I like this expression much
better. If a variable Z depends on a variable Y, which itself depends on a
variable X, then Z depends on X as well, obviously, through the intermediate
variable Y. In this case, the chain rule is expressed as if you want dZ by dX,
then you take dZ by dY and multiply it by dY by dX. The chain rule
fundamentally tells you how we chain these derivatives together correctly. So
to differentiate through a function composition, we have to apply a
multiplication of those derivatives. That's what the chain rule is telling us.
There's a nice little intuitive explanation here, which I also think is kind of
cute. The chain rule states that knowing the instantaneous rate of change of Z
with respect to Y and Y relative to X allows one to calculate the instantaneous
rate of change of Z relative to X as a product of those two rates of change.
Simply, the product of those two. Here's a good one. If a car travels twice as
fast as a bicycle and the bicycle is four times as fast as walking men, then
the car travels two times four, eight times as fast as the men. This makes it
clear that multiplying is the correct thing to do. So the car is twice as fast
as a bicycle, and the bicycle is four times as fast as a man. The car will be
eight times as fast as the man. We can take these intermediate rates of change,
if you will, and multiply them together. This justifies the chain rule
intuitively. So have a look at the chain rule. Here, really what it means for
us is there's a very simple recipe for deriving what we want, which is dL by
dC. What we have so far is we know what is the impact of D on L so we know dL
by dD, the derivative of L with respect to D. We know that that's -2, and
because of this local reasoning that we've done here, we know dD by dC. So how
does C impact D? In particular, this is a plus node, so the local derivative is
simply 1.0; it's very simple. The chain rule tells us that dL by dC, going
through this intermediate variable, will just be simply dL by dD times dD by
dC. That's the chain rule. This is identical to what's happening here, except Z
is RL, Y is RD, and X is RC. We literally just have to multiply these. Since
these local derivatives, like dD by dC, are just 1, we basically just copy over
dL by dD because this is just times one. So what is it? Because dL by dD is -2,
what is dL by dC? Well, it's the local gradient 1.0 times dL by dD, which is
-2. So literally, what a plus node does is that it routes the gradient, because
the plus node's local derivatives are just one. Therefore, in the chain rule, 1
times dL by dD is just dL by dD. That derivative routes to both C and to E in
this case. We have that E.grad, or let's start with C, since that's the one
we've looked at, is -2 times 1, which is -2. In the same way, by symmetry,
E.grad will be -2; that's the claim. We can set those; we can redraw and see
how we just assign that to -2. So this backpropagating signal carries the
information of what the derivative of L with respect to all the intermediate
nodes is. We can imagine it almost like flowing backward through the graph, and
a plus node will simply distribute the derivative to all the children nodes of
it. This is the claim, and now let's verify it. So let me remove the plus h
from before, and instead, what we're going to do is we want to increment C. So
C.data will be incremented by H, and when I run this, we expect to see -2. Of
course, for E, we expect to see -2 as well. Those are the derivatives of these
internal nodes, and now we're going to recurse our way backward again and apply
the chain rule. Here we go: our second application of the chain rule will be
applied all the way through the graph, which just happens to have one more node
remaining. We have that dL by dE, as we have just calculated, is -2. So we know
that. We know the derivative of L with respect to E. Now we want dL by dA,
right? The chain rule tells us that that's just dL by dE, -2, times the local
gradient. So what is the local gradient? Basically, dE by dA. We have to look
at that. So I'm a little times node inside a massive graph, and I only know
that I did A times B and produced an E. Now what is dE by dA and dE by dB?
That's the only thing I know about. That's my local gradient. Since we have
that E is A times B, we're asking, what is dE by dA? Of course, we just did
that here. We had A times, so I'm not going to re-derive it. But to
differentiate this with respect to A, you'll just get B, right? The value of B,
which in this case is -3.0.

So we have that dL by dA, let me just do it right here. We have that A.grad,
and we are applying the chain rule. Here is dL by dE, which we see here is -2,
times what is dE by dA? It's the value of B, which is -3. That's it, and then
we have B.grad is again dL by dE, which is -2, just the same way times what is
dE by dB? It's the value of A, which is 2.0. That's the value of A. These are
our claimed derivatives. Let's redraw, and we see here that A.grad turns out to
be 6 because that's -2 times -3. B.grad is -2 times 2, which is -4. So those
are our claims. Let's delete this, and let's verify them. We have A here,
A.data plus equals H. So the claim is that A.grad is 6. Let's verify, 6. We
have B.data plus equals H. So nudging B by H and looking at what happens, we
claim it's -4. Indeed, it's -4, plus minus again float oddness, and that's it.
That was the manual backpropagation all the way from here to all the leaf
nodes, and I've done it piece by piece. Really all we've done is, as you saw,
we iterated through all the nodes one by one and locally applied the chain
rule. We always know the derivative of L with respect to this little output,
and then we look at how this output was produced. This output was produced
through some operation, and we have the pointers to the children nodes of this
operation. In this little operation, we know what the local derivatives are,
and we just multiply them onto the derivative. We go through and recursively
multiply on the local derivatives. That's what backpropagation is. It's just a
recursive application of chain rule backwards through the computation graph.